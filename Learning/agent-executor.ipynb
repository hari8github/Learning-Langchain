{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9588a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = \"qwen/qwen3-32b\"\n",
    "\n",
    "llm = ChatGroq(model = model, temperature = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d2d1a8",
   "metadata": {},
   "source": [
    "When we talk about agents, a significant part of an \"agent\" is simple code logic,\n",
    "iteratively rerunning LLM calls and processing their output. The exact logic varies\n",
    "significantly, but one well-known example is the **ReAct** agent.\n",
    "\n",
    "![ReAct process](https://www.aurelio.ai/_next/image?url=%2Fimages%2Fposts%2Fai-agents%2Fai-agents-00.png&w=640&q=75)\n",
    "\n",
    "**Re**ason + **Act**ion (ReAct) agents use iterative _reasoning_ and _action_ steps to\n",
    "incorporate chain-of-thought and tool-use into their execution. During the _reasoning_\n",
    "step, the LLM generates the steps to take to answer the query. Next, the LLM generates\n",
    "the _action_ input, which our code logic parses into a tool call.\n",
    "\n",
    "![Agentic graph of ReAct](https://www.aurelio.ai/_next/image?url=%2Fimages%2Fposts%2Fai-agents%2Fai-agents-01.png&w=640&q=75)\n",
    "\n",
    "Following our action step, we get an observation from the tool call. Then, we feed the\n",
    "observation back into the agent executor logic for a final answer or further reasoning\n",
    "and action steps.\n",
    "\n",
    "The agent and agent executor we will be building will follow this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a079b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools.\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y:float) -> float:\n",
    "    \"\"\"Add x and y\"\"\"\n",
    "\n",
    "    return x+y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract x from y\"\"\"\n",
    "\n",
    "    return y-x\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply x and y\"\"\"\n",
    "\n",
    "    return x*y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise x to the power of y\"\"\"\n",
    "\n",
    "    return x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f7253c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description='Add x and y', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x000002400C811DC0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174aff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add.name='add'\n",
      "add.description='Add x and y'\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name=}\\n{add.description=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f2e7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Raise x to the power of y',\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'exponentiate',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754eec36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\" : 5, \\\"y\\\" : 2}\"\n",
    "llm_output_dict = json.loads(llm_output_string)\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e751412d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddd8bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtract.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3e58a",
   "metadata": {},
   "source": [
    "We need this agent to remember previous interactions within the conversation. To do that, we will use the `ChatPromptTemplate` with a system message, a placeholder for our chat history, a placeholder for the user query, and finally a placeholder for the agent scratchpad.\n",
    "\n",
    "The agent scratchpad is where the agent writes its notes as it works through multiple internal thought and tool-use steps to produce a final output for the user. This scratchpad is a list of messages with alternating roles of `ai` (for the tool call) and `tool` (for the tool execution output). Both message types require a `tool_call_id` field which is used to link the respective AI and tool messages - this can be required when we many tool calls happening in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "066fa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided in the \"\n",
    "        \"'scratchpad' below. If you have an answer in the \"\n",
    "        \"scratchpad you should not use any more tools and \"\n",
    "        \"instead answer directly to the user.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1323411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "# define the agent runnable\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"auto\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1636bf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What is 10 + 10\". Let me see. I need to use the tools provided to answer this. The available functions are add, subtract, multiply, and exponentiate. The question is straightforward addition. So I should use the add function. The parameters are x and y, both 10. Let me make sure the function requires them. The add function\\'s parameters are x and y, both numbers. So I\\'ll call add with x=10 and y=10. That should give the result 20. I don\\'t need any other tools here. Just apply the add function.\\n', 'tool_calls': [{'id': 'ata6tdsda', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 165, 'prompt_tokens': 429, 'total_tokens': 594, 'completion_time': 0.630963996, 'prompt_time': 0.02675479, 'queue_time': 0.126024969, 'total_time': 0.657718786}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--f55665ce-bb95-46a4-9b3d-18be6df2fb60-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'ata6tdsda', 'type': 'tool_call'}], usage_metadata={'input_tokens': 429, 'output_tokens': 165, 'total_tokens': 594})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9acb68f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': 'ata6tdsda',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87acf9",
   "metadata": {},
   "source": [
    "From here, we have the tool `name` that our LLM wants to use and the `args` that it\n",
    "wants to pass to that tool. We can see that the tool `add` is being used with the\n",
    "arguments `x=10` and `y=10`. The `agent.invoke` method has _not_ executed the tool\n",
    "function; we need to write that part of the agent code ourselves.\n",
    "\n",
    "Executing the tool code requires two steps:\n",
    "\n",
    "1. Map the tool `name` to the tool function.\n",
    "\n",
    "2. Execute the tool function with the generated `args`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91a73663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add': <function __main__.add(x: float, y: float) -> float>,\n",
       " 'subtract': <function __main__.subtract(x: float, y: float) -> float>,\n",
       " 'multiply': <function __main__.multiply(x: float, y: float) -> float>,\n",
       " 'exponentiate': <function __main__.exponentiate(x: float, y: float) -> float>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tool name to function mapping\n",
    "\n",
    "name2tool = {tool.name : tool.func for tool in tools}\n",
    "name2tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "678263db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "575c3a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of 10 + 10 is **20**.', additional_kwargs={'reasoning_content': 'Okay, the user asked \"What is 10 + 10\". I need to use the add function here. Let me check the tools available. The add function takes two numbers, x and y. So I\\'ll call add with x=10 and y=10. The result from the tool was 20. That\\'s straightforward. I just need to present the answer clearly. Make sure to state the calculation and the result. No other tools are needed here since it\\'s a simple addition. Just confirm the numbers and the operation. Yep, everything checks out. The answer is 20.\\n'}, response_metadata={'token_usage': {'completion_tokens': 147, 'prompt_tokens': 476, 'total_tokens': 623, 'completion_time': 0.545555853, 'prompt_time': 0.029417441, 'queue_time': 0.134094188, 'total_time': 0.574973294}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f5fcebc1-fd90-4d7b-99f0-f8fc11d6073c-0', usage_metadata={'input_tokens': 476, 'output_tokens': 147, 'total_tokens': 623})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_exec_content}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c70b93",
   "metadata": {},
   "source": [
    "Despite having the answer in our `agent_scratchpad`, the LLM still tries to use the tool\n",
    "_again_. This behaviour happens because we bonded the tools to the LLM with\n",
    "`tool_choice=\"any\"`. When we set `tool_choice` to `\"any\"` or `\"required\"`, we tell the\n",
    "LLM that it _MUST_ use a tool, i.e., it cannot provide a final answer.\n",
    "\n",
    "There's two options to fix this:\n",
    "\n",
    "1. Set `tool_choice=\"auto\"` to tell the LLM that it can choose to use a tool or provide\n",
    "a final answer.\n",
    "\n",
    "2. Create a `final_answer` tool - we'll explain this shortly.\n",
    "\n",
    "First, let's try option **1**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1eb4bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\" : lambda x: x[\"input\"],\n",
    "        \"chat_history\" : lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice = \"auto\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce472df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What is 10 + 10\". Let me see. I need to use the tools provided to answer this. The available functions are add, subtract, multiply, and exponentiate. The question is about addition, so the add function is the right choice. The parameters required are x and y, both numbers. Here, x is 10 and y is 10. So I should call the add function with these values. Let me double-check the function\\'s parameters to make sure. Yep, add takes x and y as numbers. So the tool call should be add with x=10 and y=10. No other functions are needed here. The answer should be 20.\\n', 'tool_calls': [{'id': '46gdz36as', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 183, 'prompt_tokens': 429, 'total_tokens': 612, 'completion_time': 0.323311479, 'prompt_time': 0.028514668, 'queue_time': 0.125377082, 'total_time': 0.351826147}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--f3adbc58-0cf2-4165-8159-76d453feee6a-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': '46gdz36as', 'type': 'tool_call'}], usage_metadata={'input_tokens': 429, 'output_tokens': 183, 'total_tokens': 612})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5173616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of 10 + 10 is **20**.', additional_kwargs={'reasoning_content': 'Okay, the user asked \"What is 10 + 10\". I need to use the add function here. Let me check the tools available. The add function takes two numbers, x and y. So I\\'ll call add with x=10 and y=10. The result from the tool was 20. That\\'s straightforward. I just need to present the answer clearly. Let me make sure there\\'s no trick or additional steps needed. The user probably just wants the sum. So the answer is 20.\\n'}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 476, 'total_tokens': 608, 'completion_time': 0.436795241, 'prompt_time': 0.030679978, 'queue_time': 0.125519582, 'total_time': 0.467475219}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7fb823a5-3dd6-4519-8073-e6191082c77e-0', usage_metadata={'input_tokens': 476, 'output_tokens': 132, 'total_tokens': 608})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_output = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_output}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d6c78",
   "metadata": {},
   "source": [
    "option 2 - final answer tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7833913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f90e5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [final_answer, add, subtract, multiply, exponentiate]\n",
    "\n",
    "# we need to update our name2tool mapping too\n",
    "name2tool = {tool.name: tool.func for tool in tools}\n",
    "\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcfb92b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': 'xgv6c64c4',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f60ad45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user asked \"What is 10 + 10\". I used the add function with x=10 and y=10. The result was 20. Now I need to present the final answer. Since the tool already gave the correct result, I just need to state it clearly. Make sure to mention the tools used, which is the add function here. No other tools are needed. Just confirm the calculation and provide the answer in a natural sentence.\\n', 'tool_calls': [{'id': '7ea4zmchy', 'function': {'arguments': '{\"answer\":\"The result of 10 + 10 is 20.\",\"tools_used\":[\"add\"]}', 'name': 'final_answer'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 159, 'prompt_tokens': 603, 'total_tokens': 762, 'completion_time': 0.436434388, 'prompt_time': 0.036469632, 'queue_time': 0.134849206, 'total_time': 0.47290402}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8ee077a2-bad3-40c2-bed2-0c64f2101c30-0', tool_calls=[{'name': 'final_answer', 'args': {'answer': 'The result of 10 + 10 is 20.', 'tools_used': ['add']}, 'id': '7ea4zmchy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 603, 'output_tokens': 159, 'total_tokens': 762})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_out = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_out}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcbac489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'final_answer',\n",
       "  'args': {'answer': 'The result of 10 + 10 is 20.', 'tools_used': ['add']},\n",
       "  'id': '7ea4zmchy',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8b9555a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The result of 10 + 10 is 20.', 'tools_used': ['add']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c82e62",
   "metadata": {},
   "source": [
    "Building a custom agent execution tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "616dc10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "class CustomAgentExecutor:\n",
    "    chat_history: list[BaseMessage]\n",
    "\n",
    "    def __init__(self, max_iterations : int = 3):\n",
    "        self.chat_history = []\n",
    "        self.max_iterations = max_iterations\n",
    "        self.agent : RunnableSerializable = (\n",
    "            {\n",
    "                \"input\" : lambda x: x[\"input\"],\n",
    "                \"chat_history\" : lambda x : x[\"chat_history\"],\n",
    "                \"agent_scratchpad\" : lambda x: x.get(\"agent_scratchpad\", [])\n",
    "            }\n",
    "            | prompt\n",
    "            | llm.bind_tools(tools, tool_choice = \"any\")\n",
    "        )\n",
    "\n",
    "    def invoke(self, input: str) -> dict:\n",
    "        # invoke the agent but we do this iteratively in a loop until\n",
    "        # reaching the final answer\n",
    "        count = 0\n",
    "        agent_scratchpad = []\n",
    "        while count < self.max_iterations:\n",
    "            tool_call = self.agent.invoke({\n",
    "                \"input\" : input,\n",
    "                \"chat_history\" : self.chat_history,\n",
    "                \"agent_scratchpad\" : agent_scratchpad\n",
    "            })\n",
    "            # add initial tool call to scratchpad\n",
    "            agent_scratchpad.append(tool_call)\n",
    "            # otherwise we execute the tool and add it's output\n",
    "            # to the agent scratchpad.\n",
    "            tool_name = tool_call.tool_calls[0][\"name\"]\n",
    "            tool_args = tool_call.tool_calls[0][\"args\"]\n",
    "            tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
    "            tool_out = name2tool[tool_name](**tool_args)\n",
    "            # add the tools output to the agent scratchpad\n",
    "            tool_exec = ToolMessage(\n",
    "                content = f\"{tool_out}\",\n",
    "                tool_call_id = tool_call_id\n",
    "            )\n",
    "            agent_scratchpad.append(tool_exec)\n",
    "            # add a print so we can see the intermediate steps\n",
    "            print(f\"{count}: {tool_name}({tool_args})\")\n",
    "            count +=1\n",
    "            # if the tool call is the final answer tool, we stop.\n",
    "            if tool_name == \"final_answer\":\n",
    "                break\n",
    "        \n",
    "        # add the final output to the chat history\n",
    "        final_answer = tool_out[\"answer\"]\n",
    "        self.chat_history.extend([\n",
    "            HumanMessage(content = input),\n",
    "            AIMessage(content = final_answer)\n",
    "        ])\n",
    "\n",
    "        # return the answer in dict form\n",
    "        return json.dumps(tool_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8d56da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = CustomAgentExecutor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87f65328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: add({'x': 10, 'y': 10})\n",
      "1: final_answer({'answer': 'The result of 10 + 10 is 20.', 'tools_used': ['add']})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"answer\": \"The result of 10 + 10 is 20.\", \"tools_used\": [\"add\"]}'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(input=\"What is 10 + 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0e342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
