{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9588a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = \"qwen/qwen3-32b\"\n",
    "\n",
    "llm = ChatGroq(model = model, temperature = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d2d1a8",
   "metadata": {},
   "source": [
    "When we talk about agents, a significant part of an \"agent\" is simple code logic,\n",
    "iteratively rerunning LLM calls and processing their output. The exact logic varies\n",
    "significantly, but one well-known example is the **ReAct** agent.\n",
    "\n",
    "![ReAct process](https://www.aurelio.ai/_next/image?url=%2Fimages%2Fposts%2Fai-agents%2Fai-agents-00.png&w=640&q=75)\n",
    "\n",
    "**Re**ason + **Act**ion (ReAct) agents use iterative _reasoning_ and _action_ steps to\n",
    "incorporate chain-of-thought and tool-use into their execution. During the _reasoning_\n",
    "step, the LLM generates the steps to take to answer the query. Next, the LLM generates\n",
    "the _action_ input, which our code logic parses into a tool call.\n",
    "\n",
    "![Agentic graph of ReAct](https://www.aurelio.ai/_next/image?url=%2Fimages%2Fposts%2Fai-agents%2Fai-agents-01.png&w=640&q=75)\n",
    "\n",
    "Following our action step, we get an observation from the tool call. Then, we feed the\n",
    "observation back into the agent executor logic for a final answer or further reasoning\n",
    "and action steps.\n",
    "\n",
    "The agent and agent executor we will be building will follow this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a079b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools.\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y:float) -> float:\n",
    "    \"\"\"Add x and y\"\"\"\n",
    "\n",
    "    return x+y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract x from y\"\"\"\n",
    "\n",
    "    return y-x\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply x and y\"\"\"\n",
    "\n",
    "    return x*y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise x to the power of y\"\"\"\n",
    "\n",
    "    return x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f7253c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description='Add x and y', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x000001826F945430>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174aff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add.name='add'\n",
      "add.description='Add x and y'\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name=}\\n{add.description=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f2e7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Raise x to the power of y',\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'exponentiate',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "754eec36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\" : 5, \\\"y\\\" : 2}\"\n",
    "llm_output_dict = json.loads(llm_output_string)\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e751412d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ddd8bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtract.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3e58a",
   "metadata": {},
   "source": [
    "We need this agent to remember previous interactions within the conversation. To do that, we will use the `ChatPromptTemplate` with a system message, a placeholder for our chat history, a placeholder for the user query, and finally a placeholder for the agent scratchpad.\n",
    "\n",
    "The agent scratchpad is where the agent writes its notes as it works through multiple internal thought and tool-use steps to produce a final output for the user. This scratchpad is a list of messages with alternating roles of `ai` (for the tool call) and `tool` (for the tool execution output). Both message types require a `tool_call_id` field which is used to link the respective AI and tool messages - this can be required when we many tool calls happening in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "066fa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided in the \"\n",
    "        \"'scratchpad' below. If you have an answer in the \"\n",
    "        \"scratchpad you should not use any more tools and \"\n",
    "        \"instead answer directly to the user.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name = \"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name = \"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1323411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "# define the agent runnable\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\" : lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice = \"any\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1636bf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What is 10 times 10\". Let me see. The available functions are add, subtract, multiply, and exponentiate. The question is about multiplication, so the correct function here would be multiply. The parameters needed are x and y, both numbers. Here, x is 10 and y is 10. So I should call the multiply function with these values. Let me double-check to make sure I\\'m not mixing up any operations. Yeah, multiply is the right choice. The result should be 100. I don\\'t need to use any other functions here.\\n', 'tool_calls': [{'id': 'bvqn7tj40', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 160, 'prompt_tokens': 429, 'total_tokens': 589, 'completion_time': 0.355998387, 'prompt_time': 0.036793107, 'queue_time': 0.047199173, 'total_time': 0.392791494}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--158283a3-9e4e-41df-ad60-be20ba5a6428-0', tool_calls=[{'name': 'multiply', 'args': {'x': 10, 'y': 10}, 'id': 'bvqn7tj40', 'type': 'tool_call'}], usage_metadata={'input_tokens': 429, 'output_tokens': 160, 'total_tokens': 589})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke(\n",
    "    {\n",
    "        \"input\" : \"What is 10 times 10\", \"chat_history\" : []\n",
    "    }\n",
    ")\n",
    "\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9acb68f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': 'bvqn7tj40',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87acf9",
   "metadata": {},
   "source": [
    "From here, we have the tool `name` that our LLM wants to use and the `args` that it\n",
    "wants to pass to that tool. We can see that the tool `add` is being used with the\n",
    "arguments `x=10` and `y=10`. The `agent.invoke` method has _not_ executed the tool\n",
    "function; we need to write that part of the agent code ourselves.\n",
    "\n",
    "Executing the tool code requires two steps:\n",
    "\n",
    "1. Map the tool `name` to the tool function.\n",
    "\n",
    "2. Execute the tool function with the generated `args`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91a73663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add': <function __main__.add(x: float, y: float) -> float>,\n",
       " 'subtract': <function __main__.subtract(x: float, y: float) -> float>,\n",
       " 'multiply': <function __main__.multiply(x: float, y: float) -> float>,\n",
       " 'exponentiate': <function __main__.exponentiate(x: float, y: float) -> float>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tool name to function mapping\n",
    "\n",
    "name2tool = {tool.name : tool.func for tool in tools}\n",
    "name2tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "678263db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "575c3a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user asked \"What is 10 minus 10?\" Let me see. I need to figure out which tool to use here. The available functions are add, subtract, multiply, and exponentiate.\\n\\nThe user is asking for subtraction, so the correct function should be subtract. But wait, in the previous interaction, the assistant used the multiply function by mistake. The user\\'s current question is the same as before, but maybe they want the correct answer this time. \\n\\nLet me check the parameters. The subtract function requires x and y. The question is 10 minus 10, so x is 10 and y is 10. The correct tool is subtract, not multiply. The previous tool call was wrong, so I should correct that. \\n\\nI need to make sure to call the subtract function with x=10 and y=10. The result should be 0. Let me structure the tool call properly. The function name is subtract, and the arguments are x:10, y:10. \\n\\nNo other tools are needed here. Just the subtract function. I\\'ll output the tool call accordingly.\\n', 'tool_calls': [{'id': 'q9gw2evb8', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'subtract'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 268, 'prompt_tokens': 477, 'total_tokens': 745, 'completion_time': 1.10563217, 'prompt_time': 0.05158269, 'queue_time': 0.04717161, 'total_time': 1.15721486}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0265d83a-7220-49ce-85e7-3d6891f7fbb8-0', tool_calls=[{'name': 'subtract', 'args': {'x': 10, 'y': 10}, 'id': 'q9gw2evb8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 477, 'output_tokens': 268, 'total_tokens': 745})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content = f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_exec_content}\",\n",
    "    tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\" : \"What is 10 minus 10\",\n",
    "    \"chat_history\" : [],\n",
    "    \"agent_scratchpad\" : [tool_call, tool_exec]\n",
    "})\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c70b93",
   "metadata": {},
   "source": [
    "Despite having the answer in our `agent_scratchpad`, the LLM still tries to use the tool\n",
    "_again_. This behaviour happens because we bonded the tools to the LLM with\n",
    "`tool_choice=\"any\"`. When we set `tool_choice` to `\"any\"` or `\"required\"`, we tell the\n",
    "LLM that it _MUST_ use a tool, i.e., it cannot provide a final answer.\n",
    "\n",
    "There's two options to fix this:\n",
    "\n",
    "1. Set `tool_choice=\"auto\"` to tell the LLM that it can choose to use a tool or provide\n",
    "a final answer.\n",
    "\n",
    "2. Create a `final_answer` tool - we'll explain this shortly.\n",
    "\n",
    "First, let's try option **1**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1eb4bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\" : lambda x: x[\"input\"],\n",
    "        \"chat_history\" : lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice = \"auto\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce472df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What is 10 minus 10?\" Let me see. I need to figure out which tool to use here. The available functions are add, subtract, multiply, and exponentiate.\\n\\nThe question is about subtraction, so the subtract function is the right choice. The parameters for subtract are x and y, where x is the number being subtracted from, and y is the number subtracted. Wait, actually, the function description says \"Subtract x from y\", which might mean that the function subtracts x from y, making the result y - x. So in this case, the user is asking 10 minus 10, which would be y - x where y is 10 and x is 10. So I need to set x to 10 and y to 10 in the subtract function. Let me double-check that. If the function is called subtract and the parameters are x and y, but the description says \"Subtract x from y\", then the operation is y - x. So for 10 minus 10, y is 10 and x is 10. Therefore, the arguments should be x: 10, y: 10. The result would be 0. I should call the subtract function with those parameters.\\n', 'tool_calls': [{'id': 'rykbaagp6', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'subtract'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 306, 'prompt_tokens': 429, 'total_tokens': 735, 'completion_time': 0.744910859, 'prompt_time': 0.031531261, 'queue_time': 0.053634854, 'total_time': 0.77644212}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0f510a3a-1e3d-4942-ba4c-2900d7954781-0', tool_calls=[{'name': 'subtract', 'args': {'x': 10, 'y': 10}, 'id': 'rykbaagp6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 429, 'output_tokens': 306, 'total_tokens': 735})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call= agent.invoke(\n",
    "    {\n",
    "        \"input\" : \"What is 10 minus 10\",\n",
    "        \"chat_history\" : []\n",
    "    }\n",
    ")\n",
    "\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5173616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='10 minus 10 equals 0.', additional_kwargs={'reasoning_content': 'Okay, the user asked \"What is 10 minus 10?\" So I need to subtract 10 from 10. Let me check the available tools. There\\'s a subtract function that takes x and y. I\\'ll call that with x=10 and y=10. The result from the tool was 0. So the answer is 0. I should just state that clearly.\\n'}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 475, 'total_tokens': 575, 'completion_time': 0.153876734, 'prompt_time': 0.03037699, 'queue_time': 0.053233138, 'total_time': 0.184253724}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--92599875-e101-4219-9880-4fc58548631c-0', usage_metadata={'input_tokens': 475, 'output_tokens': 100, 'total_tokens': 575})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_output = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content = f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_output}\",\n",
    "    tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\" : \"What is 10 minus 10\",\n",
    "    \"chat_history\" : [],\n",
    "    \"agent_scratchpad\" : [tool_call, tool_exec]\n",
    "})\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d6c78",
   "metadata": {},
   "source": [
    "option 2 - final answer tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7833913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f90e5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [final_answer, add, subtract, multiply, exponentiate]\n",
    "\n",
    "# we need to update our name2tool mapping too\n",
    "name2tool = {tool.name: tool.func for tool in tools}\n",
    "\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcfb92b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': 'j7ahk9ngm',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f60ad45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user asked \"What is 10 + 10\". I used the add function with x=10 and y=10. The result was 20. Now I need to present the final answer. Since the tool already gave the correct result, I just need to state it clearly. Make sure to mention the tools used, which is the add function here. No other tools are needed. Just confirm the calculation and provide the answer in a natural sentence.\\n', 'tool_calls': [{'id': 'dhkqwavxq', 'function': {'arguments': '{\"answer\":\"The result of 10 + 10 is 20.\",\"tools_used\":[\"add\"]}', 'name': 'final_answer'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 159, 'prompt_tokens': 603, 'total_tokens': 762, 'completion_time': 0.326689163, 'prompt_time': 0.08433144, 'queue_time': 0.049523569, 'total_time': 0.411020603}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6ee109ca-31f3-4bda-b900-9a83f4352e56-0', tool_calls=[{'name': 'final_answer', 'args': {'answer': 'The result of 10 + 10 is 20.', 'tools_used': ['add']}, 'id': 'dhkqwavxq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 603, 'output_tokens': 159, 'total_tokens': 762})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_out = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_out}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fcbac489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'final_answer',\n",
       "  'args': {'answer': 'The result of 10 + 10 is 20.', 'tools_used': ['add']},\n",
       "  'id': 'dhkqwavxq',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8b9555a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The result of 10 + 10 is 20.', 'tools_used': ['add']}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616dc10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
