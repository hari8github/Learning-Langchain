{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d0a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48840f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x000001E909730EE0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32616915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add.name='add'\n",
      "add.description=\"Add 'x' and 'y'.\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name=}\\n{add.description=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c97aec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Add 'x' and 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d9a34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\" : 2}\" #output from LLM\n",
    "llm_output_dict = json.loads(llm_output_string) # load as dictionary\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06006903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 \n",
      " 25\n"
     ]
    }
   ],
   "source": [
    "print(add.func(**llm_output_dict), \"\\n\",\n",
    "exponentiate.func(**llm_output_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f69001",
   "metadata": {},
   "source": [
    "We're going to construct a simple tool calling agent. We will use **L**ang**C**hain **E**pression **L**anguage (LCEL) to construct the agent. We will cover LCEL more in the next chapter, but for now - all we need to know is that our agent will be constructed using syntax and components like so:\n",
    "\n",
    "\n",
    "```\n",
    "agent = (\n",
    "    <input parameters, including chat history and user query>\n",
    "    | <prompt>\n",
    "    | <LLM with tools>\n",
    ")\n",
    "```\n",
    "\n",
    "We need this agent to remember previous interactions within the conversation. To do that, we will use the `ChatPromptTemplate` with a system message, a placeholder for our chat history, a placeholder for the user query, and finally a placeholder for the agent scratchpad.\n",
    "\n",
    "The agent scratchpad is where the agent will write it's _\"notes\"_ as it is working through multiple internal thought and tool-use steps to produce a final output to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84968fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You're a helpful assistant\"),\n",
    "    MessagesPlaceholder(variable_name = \"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d5d11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name = \"qwen/qwen3-32b\",\n",
    "    temperature = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ea6ef",
   "metadata": {},
   "source": [
    "When creating an agent we need to add conversational memory to make the agent remember previous interactions. We'll be using the older `ConversationBufferMemory` class rather than the newer `RunnableWithMessageHistory` — the reason being that we will also be using the older `create_tool_calling_agent` and `AgentExecutor` method and class.\n",
    "\n",
    "In the `05` chapter we will be using the newer `RunnableWithMessageHistory` class as we'll be building a custom `AgentExecutor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6629badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harivenkat\\AppData\\Local\\Temp\\ipykernel_20856\\1669027029.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key = \"chat_history\", # algins with messagePlaceholder variable_name\n",
    "    return_messages = True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38fc68f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm = llm,\n",
    "    tools = tools,\n",
    "    prompt = prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a765dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolAgentAction(tool='multiply', tool_input={'x': 11.676, 'y': 2.32}, log=\"\\nInvoking: `multiply` with `{'x': 11.676, 'y': 2.32}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking to multiply 11.676 by 2.32. Let me check the available functions. There\\'s a multiply function that takes two numbers, x and y. So I need to call that. The parameters are x and y, both numbers. The user provided 11.676 and 2.32. I should structure the tool call with these values. Let me make sure I have the function name right. The description says \"Multiply \\'x\\' and \\'y\\'\", so the name is \"multiply\". The arguments should be x: 11.676 and y: 2.32. I need to present this in JSON format within the tool_call tags. Let me double-check the syntax to avoid any errors.\\n', 'tool_calls': [{'id': 'pfe8x9hwb', 'function': {'arguments': '{\"x\":11.676,\"y\":2.32}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 201, 'prompt_tokens': 467, 'total_tokens': 668, 'completion_time': 0.351839275, 'prompt_time': 0.042876756, 'queue_time': 0.04779656, 'total_time': 0.394716031}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--24c4243e-aab3-4692-af63-e59d870dc019-0', tool_calls=[{'name': 'multiply', 'args': {'x': 11.676, 'y': 2.32}, 'id': 'pfe8x9hwb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 467, 'output_tokens': 201, 'total_tokens': 668})], tool_call_id='pfe8x9hwb')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\n",
    "    \"input\" : \"What is 11.676 multiplied by 2.32?\",\n",
    "    \"chat_history\" : memory.chat_memory.messages,\n",
    "    \"intermediate_steps\" : [] # agent will append its internal steps.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d2c452",
   "metadata": {},
   "source": [
    "Here, we can see the LLM has generated that we should use the `multiply` tool and the tool input should be `{\"x\": 10.7, \"y\": 7.68}`. However, the tool is not executed. For that to happen we need an agent execution loop, which will handle the multiple iterations of generation to tool calling to generation, etc.\n",
    "\n",
    "We use the `AgentExecutor` class to handle the execution loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f02f2052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent = agent,\n",
    "    tools = tools,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc403e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'x': 11.676, 'y': 2.32}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m27.08832\u001b[0m\u001b[32;1m\u001b[1;3mThe result of multiplying 11.676 by 2.32 is **27.08832**.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 11.676 multiplied by 2.32?',\n",
       " 'chat_history': [HumanMessage(content='What is 11.676 multiplied by 2.32?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of multiplying 11.676 by 2.32 is **27.08832**.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'The result of multiplying 11.676 by 2.32 is **27.08832**.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\" : \"What is 11.676 multiplied by 2.32?\",\n",
    "    \"chat_history\" : memory.chat_memory.messages\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5178bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.08832"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11.676 * 2.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a484eca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello, Hari! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My name is Hari',\n",
       " 'chat_history': [HumanMessage(content='What is 11.676 multiplied by 2.32?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of multiplying 11.676 by 2.32 is **27.08832**.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Hari', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello, Hari! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Hello, Hari! How can I assist you today?'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\" : \"My name is Hari\",\n",
    "    \"chat_history\" : memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04b530fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe result of the expression $9 + 10 - (4 \\times 2)^3$ is **-493**. \n",
      "\n",
      "**Step-by-step breakdown:**\n",
      "1. **Parentheses:** $4 \\times 2 = 8$\n",
      "2. **Exponent:** $8^3 = 512$\n",
      "3. **Addition/Subtraction:** $9 + 10 - 512 = 19 - 512 = -493$\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 9+10-(4*2)**3',\n",
       " 'chat_history': [HumanMessage(content='What is 11.676 multiplied by 2.32?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of multiplying 11.676 by 2.32 is **27.08832**.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Hari', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello, Hari! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is 9+10-(4*2)**3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of the expression $9 + 10 - (4 \\\\times 2)^3$ is **-493**. \\n\\n**Step-by-step breakdown:**\\n1. **Parentheses:** $4 \\\\times 2 = 8$\\n2. **Exponent:** $8^3 = 512$\\n3. **Addition/Subtraction:** $9 + 10 - 512 = 19 - 512 = -493$', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'The result of the expression $9 + 10 - (4 \\\\times 2)^3$ is **-493**. \\n\\n**Step-by-step breakdown:**\\n1. **Parentheses:** $4 \\\\times 2 = 8$\\n2. **Exponent:** $8^3 = 512$\\n3. **Addition/Subtraction:** $9 + 10 - 512 = 19 - 512 = -493$'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\" : \"What is 9+10-(4*2)**3\",\n",
    "    \"chat_history\" : memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd28c451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-493"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9+10-(4*2)**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e85f63a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is **Hari**! 😊 How can I assist you today, Hari?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name',\n",
       " 'chat_history': [HumanMessage(content='What is 11.676 multiplied by 2.32?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of multiplying 11.676 by 2.32 is **27.08832**.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Hari', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello, Hari! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is 9+10-(4*2)**3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of the expression $9 + 10 - (4 \\\\times 2)^3$ is **-493**. \\n\\n**Step-by-step breakdown:**\\n1. **Parentheses:** $4 \\\\times 2 = 8$\\n2. **Exponent:** $8^3 = 512$\\n3. **Addition/Subtraction:** $9 + 10 - 512 = 19 - 512 = -493$', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is **Hari**! 😊 How can I assist you today, Hari?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Your name is **Hari**! 😊 How can I assist you today, Hari?'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\" : \"What is my name\",\n",
    "    \"chat_history\" : memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb4b1216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "toolbox = load_tools(tool_names = ['serpapi'], llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e6e57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "@tool\n",
    "def get_location_from_ip():\n",
    "    \"\"\"Get the geo location based on the IP\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(\"https://ipinfo.io/json\")\n",
    "        data = response.json()\n",
    "        if 'loc' in data:\n",
    "            latitude, longitude = data['loc'].split(',')\n",
    "            data = (\n",
    "                f\"Latitude: {latitude},\\n\"\n",
    "                f\"Longitude: {longitude},\\n\"\n",
    "                f\"City: {data.get('city', 'N/A')},\\n\"\n",
    "                f\"Country: {data.get('country', 'N/A')}\"\n",
    "            )\n",
    "            return data\n",
    "        else:\n",
    "            return \"Location could not be determined\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error : {e}\"\n",
    "\n",
    "@tool\n",
    "def get_current_datetime() -> str:\n",
    "    \"\"\"Return the current date and time\"\"\"\n",
    "\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb07e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\" , \"{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ad9ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = toolbox + [get_current_datetime, get_location_from_ip]\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm = llm,\n",
    "    tools = tools,\n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent = agent,\n",
    "    tools = tools,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86a92680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_current_datetime` with `{}`\n",
      "responded: \n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m2025-08-13 18:41:24\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_location_from_ip` with `{}`\n",
      "responded: \n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLatitude: 11.0055,\n",
      "Longitude: 76.9661,\n",
      "City: Coimbatore,\n",
      "Country: IN\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Search` with `current weather Coimbatore, IN degrees Celsius`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '26', 'unit': 'Celsius', 'precipitation': '0%', 'humidity': '78%', 'wind': '16 km/h', 'location': 'Coimbatore, Tamil Nadu, India', 'date': 'Wednesday 6:00 PM', 'weather': 'Cloudy'}\u001b[0m\u001b[32;1m\u001b[1;3mThe current date and time is **August 13, 2025, 6:41:24 PM**.  \n",
      "\n",
      "The weather in **Coimbatore, Tamil Nadu, India** (as of 6:00 PM) is:  \n",
      "- **Temperature**: 26°C  \n",
      "- **Precipitation**: 0%  \n",
      "- **Humidity**: 78%  \n",
      "- **Wind**: 16 km/h  \n",
      "- **Conditions**: Cloudy  \n",
      "\n",
      "Let me know if you need further details! ☁️\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "out = agent_executor.invoke({\n",
    "    \"input\": (\n",
    "        \"I have a few questions, what is the date and time right now? \"\n",
    "        \"How is the weather where I am? Please give me degrees in Celsius\"\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b5e4064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The current date and time is **August 13, 2025, 6:41:24 PM**.  \n",
       "\n",
       "The weather in **Coimbatore, Tamil Nadu, India** (as of 6:00 PM) is:  \n",
       "- **Temperature**: 26°C  \n",
       "- **Precipitation**: 0%  \n",
       "- **Humidity**: 78%  \n",
       "- **Wind**: 16 km/h  \n",
       "- **Conditions**: Cloudy  \n",
       "\n",
       "Let me know if you need further details! ☁️"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(out[\"output\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
