{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3431e7b6",
   "metadata": {},
   "source": [
    "LangChain versions `0.0.x` consisted of various conversational memory types. Most of these are due for deprecation but still hold value in understanding the different approaches that we can take to building conversational memory.\n",
    "\n",
    "Throughout the notebook we will be referring to these _older_ memory types and then rewriting them using the recommended `RunnableWithMessageHistory` class. We will learn about:\n",
    "\n",
    "* `ConversationBufferMemory`: the simplest and most intuitive form of conversational memory, keeping track of a conversation without any additional bells and whistles.\n",
    "* `ConversationBufferWindowMemory`: similar to `ConversationBufferMemory`, but only keeps track of the last `k` messages.\n",
    "* `ConversationSummaryMemory`: rather than keeping track of the entire conversation, this memory type keeps track of a summary of the conversation.\n",
    "* `ConversationSummaryBufferMemory`: merges the `ConversationSummaryMemory` and `ConversationTokenBufferMemory` types.\n",
    "\n",
    "We'll work through each of these memory types in turn, and rewrite each one using the `RunnableWithMessageHistory` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70cecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = \"llama3-8b-8192\"\n",
    "\n",
    "llm = ChatGroq(model = model, temperature = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307e3eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harivenkat\\AppData\\Local\\Temp\\ipykernel_3860\\29041069.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(return_messages = True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "674662f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There are several ways that we can add messages to our memory, using the save_context method we can add a user query (via the input key) and the AI's response (via the output key). So, to create the following conversation:\\n\\nUser: Hi, my name is James\\nAI: Hey James, what's up? I'm an AI model called Zeta.\\nUser: I'm researching the different types of conversational memory.\\nAI: That's interesting, what are some examples?\\nUser: I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\\nAI: That's interesting, what's the difference?\\nUser: Buffer memory just stores the entire conversation, right?\\nAI: That makes sense, what about ConversationBufferWindowMemory?\\nUser: Buffer window memory stores the last k messages, dropping the rest.\\nAI: Very cool!\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"There are several ways that we can add messages to our memory, using the save_context method we can add a user query (via the input key) and the AI's response (via the output key). So, to create the following conversation:\n",
    "\n",
    "User: Hi, my name is James\n",
    "AI: Hey James, what's up? I'm an AI model called Zeta.\n",
    "User: I'm researching the different types of conversational memory.\n",
    "AI: That's interesting, what are some examples?\n",
    "User: I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\n",
    "AI: That's interesting, what's the difference?\n",
    "User: Buffer memory just stores the entire conversation, right?\n",
    "AI: That makes sense, what about ConversationBufferWindowMemory?\n",
    "User: Buffer window memory stores the last k messages, dropping the rest.\n",
    "AI: Very cool!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b22199",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hi, my name is James\"},  # user message\n",
    "    {\"output\": \"Hey James, what's up? I'm an AI model called Zeta.\"}  # AI response\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"I'm researching the different types of conversational memory.\"},  # user message\n",
    "    {\"output\": \"That's interesting, what are some examples?\"}  # AI response\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\"},  # user message\n",
    "    {\"output\": \"That's interesting, what's the difference?\"}  # AI response\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"Buffer memory just stores the entire conversation, right?\"},  # user message\n",
    "    {\"output\": \"That makes sense, what about ConversationBufferWindowMemory?\"}  # AI response\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"Buffer window memory stores the last k messages, dropping the rest.\"},  # user message\n",
    "    {\"output\": \"Very cool!\"}  # AI response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563a2ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hey James, what's up? I'm an AI model called Zeta.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c488a020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With this other method, we pass individual user and AI messages via the add_user_message and add_ai_message methods. To reproduce what we did above, we do:'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"With this other method, we pass individual user and AI messages via the add_user_message and add_ai_message methods. To reproduce what we did above, we do:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bada35b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hey James, what's up? I'm an AI model called Zeta.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.chat_memory.add_user_message(\"Hi, my name is James\")\n",
    "memory.chat_memory.add_ai_message(\"Hey James, what's up? I'm an AI model called Zeta.\")\n",
    "memory.chat_memory.add_user_message(\"I'm researching the different types of conversational memory.\")\n",
    "memory.chat_memory.add_ai_message(\"That's interesting, what are some examples?\")\n",
    "memory.chat_memory.add_user_message(\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\")\n",
    "memory.chat_memory.add_ai_message(\"That's interesting, what's the difference?\")\n",
    "memory.chat_memory.add_user_message(\"Buffer memory just stores the entire conversation, right?\")\n",
    "memory.chat_memory.add_ai_message(\"That makes sense, what about ConversationBufferWindowMemory?\")\n",
    "memory.chat_memory.add_user_message(\"Buffer window memory stores the last k messages, dropping the rest.\")\n",
    "memory.chat_memory.add_ai_message(\"Very cool!\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f122e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harivenkat\\AppData\\Local\\Temp\\ipykernel_3860\\3315403223.py:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  chain = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f52c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hey James, what's up? I'm an AI model called Zeta.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}), AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}), AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})]\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name?',\n",
       " 'history': [HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hey James, what's up? I'm an AI model called Zeta.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hey James! Your name is James, and I'm happy to chat with you about conversational memory!\", additional_kwargs={}, response_metadata={})],\n",
       " 'response': \"Hey James! Your name is James, and I'm happy to chat with you about conversational memory!\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\" : \"What is my name?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa83894",
   "metadata": {},
   "source": [
    "ConversationBufferMemory with RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5dacd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    ChatPromptTemplate    \n",
    ")\n",
    "\n",
    "system_prompt = \"You are a helpful assistant called Hari\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "        MessagesPlaceholder(variable_name = \"history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b36d5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dec4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "chat_map = {}\n",
    "def get_chat_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c764380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history = get_chat_history,\n",
    "    input_messages_key = \"query\",\n",
    "    history_messages_key = \"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a19c4646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi James! Nice to meet you! I'm Hari, your helpful assistant. How can I assist you today? Do you have any questions, need help with something, or just want to chat? I'm all ears!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 29, 'total_tokens': 75, 'completion_time': 0.036649251, 'prompt_time': 0.003791949, 'queue_time': 0.274704124, 'total_time': 0.0404412}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_343314801a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2a70c7ec-5149-4e47-85e0-5081e2d7fde3-0', usage_metadata={'input_tokens': 29, 'output_tokens': 46, 'total_tokens': 75})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\" : \"Hi!!, my name is James!!\"},\n",
    "    config = {\"session_id\": \"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e8ed803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is James!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 90, 'total_tokens': 96, 'completion_time': 0.004842927, 'prompt_time': 0.010484886, 'queue_time': 0.275507837, 'total_time': 0.015327813}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_343314801a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--23db663e-7fed-4384-9413-048f424a0fda-0', usage_metadata={'input_tokens': 90, 'output_tokens': 6, 'total_tokens': 96})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\" : \"What is my name again?\"},\n",
    "    config = {\"session_id\" : \"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d9542",
   "metadata": {},
   "source": [
    "ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751de537",
   "metadata": {},
   "source": [
    "The `ConversationBufferWindowMemory` type is similar to `ConversationBufferMemory`, but only keeps track of the last `k` messages. There are a few reasons why we would want to keep only the last `k` messages:\n",
    "\n",
    "* More messages mean more tokens are sent with each request, more tokens increases latency _and_ cost.\n",
    "\n",
    "* LLMs tend to perform worse when given more tokens, making them more likely to deviate from instructions, hallucinate, or _\"forget\"_ information provided to them. Conciseness is key to high performing LLMs.\n",
    "\n",
    "* If we keep _all_ messages we will eventually hit the LLM's context window limit, by adding a window size `k` we can ensure we never hit this limit.\n",
    "\n",
    "The buffer window solves many problems that we encounter with the standard buffer memory, while still being a very simple and intuitive form of conversational memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36db63b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harivenkat\\AppData\\Local\\Temp\\ipykernel_3860\\3678575494.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k = 8, return_messages = True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k = 8, return_messages = True)\n",
    "\n",
    "# if k = 4 it says 'response': \"I apologize, but I don't have that information.\n",
    "# if k = 8 it says  'response': 'Your name is James!'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6815b3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hey James, what's up? I'm an AI model called Zeta.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.add_user_message(\"Hi, my name is James\")\n",
    "memory.chat_memory.add_ai_message(\"Hey James, what's up? I'm an AI model called Zeta.\")\n",
    "memory.chat_memory.add_user_message(\"I'm researching the different types of conversational memory.\")\n",
    "memory.chat_memory.add_ai_message(\"That's interesting, what are some examples?\")\n",
    "memory.chat_memory.add_user_message(\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\")\n",
    "memory.chat_memory.add_ai_message(\"That's interesting, what's the difference?\")\n",
    "memory.chat_memory.add_user_message(\"Buffer memory just stores the entire conversation, right?\")\n",
    "memory.chat_memory.add_ai_message(\"That makes sense, what about ConversationBufferWindowMemory?\")\n",
    "memory.chat_memory.add_user_message(\"Buffer window memory stores the last k messages, dropping the rest.\")\n",
    "memory.chat_memory.add_ai_message(\"Very cool!\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0d6d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c96a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hey James, what's up? I'm an AI model called Zeta.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}), AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}), AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})]\n",
      "Human: what is my name again?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is my name again?',\n",
       " 'history': [HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hey James, what's up? I'm an AI model called Zeta.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})],\n",
       " 'response': 'Your name is James!'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\" : \"what is my name again?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4a62f",
   "metadata": {},
   "source": [
    "ConversationBufferWindowMemory with RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd819e",
   "metadata": {},
   "source": [
    "To implement this memory type using the `RunnableWithMessageHistory` class, we can use the same approach as before. We define our `prompt_template` and `llm` as before, and then wrap our pipeline in a `RunnableWithMessageHistory` object.\n",
    "\n",
    "For the window feature, we need to define a custom version of the `InMemoryChatMessageHistory` class that removes any messages beyond the last `k` messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dc59693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class BufferWindowMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages : list[BaseModel] = Field(default_factory = list)\n",
    "    k : int = Field(default_factory = int)\n",
    "\n",
    "    def __init__(self, k: int):\n",
    "        super().__init__(k=k)\n",
    "        print(f\"Initializing BufferWindowMessageHistory with k={k}\")\n",
    "\n",
    "    def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "        \"\"\"Add messages to the history, removing any messages beyond\n",
    "        the last `k` messages.\n",
    "        \"\"\"\n",
    "        self.messages.extend(messages)\n",
    "        self.messages = self.messages[-self.k:]\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clears the history\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb0afd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_map = {}\n",
    "\n",
    "def get_chat_history(session_id: str, k: int = 4) -> BufferWindowMessageHistory:\n",
    "    print(f\"get_chat_history called with session_id = {session_id} and k = {k}\")\n",
    "    if session_id not in chat_map:\n",
    "        chat_map[session_id] = BufferWindowMessageHistory(k=k)\n",
    "\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "327b7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "pipeline_with_history2 = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history = get_chat_history,\n",
    "    input_messages_key = \"query\",\n",
    "    history_messages_key = \"history\",\n",
    "    history_factory_config = [\n",
    "        ConfigurableFieldSpec(\n",
    "            id = \"session_id\",\n",
    "            annotation = str,\n",
    "            name = \"Session ID\",\n",
    "            description = \"The session ID to use for the chat history\",\n",
    "            default = \"id_default\"\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id = \"k\",\n",
    "            annotation = int,\n",
    "            name = \"k\",\n",
    "            description = \"the number of messages to keep in the history\",\n",
    "            default = 4\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d8261f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_chat_history called with session_id = id_k4 and k = 4\n",
      "Initializing BufferWindowMessageHistory with k=4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, James! I'm Hari, your helpful assistant. How can I assist you today? Do you have a specific question, topic you'd like to discuss, or perhaps a task you'd like me to help you with? I'm all ears!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 27, 'total_tokens': 82, 'completion_time': 0.044344162, 'prompt_time': 0.00580987, 'queue_time': 0.321504253, 'total_time': 0.050154032}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_c0b3855449', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ee3f0fcb-2a4e-422d-af8c-702d5c9e7d4f-0', usage_metadata={'input_tokens': 27, 'output_tokens': 55, 'total_tokens': 82})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history2.invoke(\n",
    "    {\"query\" : \"Hi my name is James\"},\n",
    "    config = {\"configurable\" : {\"session_id\" : \"id_k4\", \"k\": 4}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48fb28ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_k4\"].clear()\n",
    "\n",
    "# manually insert history\n",
    "chat_map[\"id_k4\"].add_user_message(\"Hi, my name is James\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"I'm an AI model called Zeta.\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"I'm researching the different types of conversational memory.\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"That's interesting, what are some examples?\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"That's interesting, what's the difference?\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"Buffer memory just stores the entire conversation, right?\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"That makes sense, what about ConversationBufferWindowMemory?\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"Buffer window memory stores the last k messages, dropping the rest.\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"Very cool!\")\n",
    "\n",
    "chat_map[\"id_k4\"].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5256df81",
   "metadata": {},
   "source": [
    "Now let's see at which `k` value our LLM remembers our name â€” from the above we can already see that with `k=4` our name is not mentioned, so when running with `k=4` we should expect the LLM to forget our name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7db96820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_chat_history called with session_id = id_k4 and k = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm afraid I don't know your name! I'm Hari, your helpful assistant, and I'm here to assist you with any questions or topics you'd like to discuss.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 85, 'total_tokens': 122, 'completion_time': 0.02970184, 'prompt_time': 0.018627459, 'queue_time': 0.396367089, 'total_time': 0.048329299}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_c0b3855449', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--1c342208-7a99-4d0c-9069-97db8e15106b-0', usage_metadata={'input_tokens': 85, 'output_tokens': 37, 'total_tokens': 122})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history2.invoke(\n",
    "    {\"query\": \"what is my name again?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"id_k4\", \"k\": 4}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adde22b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, James! I'm Hari, your helpful assistant. How can I assist you today? Do you have a specific question, task, or topic you'd like to discuss? I'm all ears!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 28, 'total_tokens': 73, 'completion_time': 0.036199137, 'prompt_time': 0.00366413, 'queue_time': 0.274607006, 'total_time': 0.039863267}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_c0b3855449', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--925abc57-9f63-4481-ac9e-35061ced2b3d-0', usage_metadata={'input_tokens': 28, 'output_tokens': 45, 'total_tokens': 73})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Now let's initialize a new session with k=14.\"\"\"\n",
    "\n",
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"Hi, my name is James\"},\n",
    "    config={\"session_id\": \"id_k14\", \"k\": 14}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5711ef5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Nice to meet you, James! I'm Hari, your helpful assistant. How can I assist you today? Do you have a specific question, task, or topic you'd like to discuss? I'm all ears!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 28, 'total_tokens': 73, 'completion_time': 0.036199137, 'prompt_time': 0.00366413, 'queue_time': 0.274607006, 'total_time': 0.039863267}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_c0b3855449', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--925abc57-9f63-4481-ac9e-35061ced2b3d-0', usage_metadata={'input_tokens': 28, 'output_tokens': 45, 'total_tokens': 73}),\n",
       " HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"We'll manually insert the remaining messages as before:\"\"\"\n",
    "\n",
    "chat_map[\"id_k14\"].add_user_message(\"I'm researching the different types of conversational memory.\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"That's interesting, what are some examples?\")\n",
    "chat_map[\"id_k14\"].add_user_message(\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"That's interesting, what's the difference?\")\n",
    "chat_map[\"id_k14\"].add_user_message(\"Buffer memory just stores the entire conversation, right?\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"That makes sense, what about ConversationBufferWindowMemory?\")\n",
    "chat_map[\"id_k14\"].add_user_message(\"Buffer window memory stores the last k messages, dropping the rest.\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"Very cool!\")\n",
    "\n",
    "chat_map[\"id_k14\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82eac7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_chat_history called with session_id = id_k14 and k = 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is James!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 207, 'total_tokens': 213, 'completion_time': 0.004868247, 'prompt_time': 0.023711761, 'queue_time': 0.268952713, 'total_time': 0.028580008}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_5b339000ab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--daef931a-8737-4664-ace8-3da3dee37771-0', usage_metadata={'input_tokens': 207, 'output_tokens': 6, 'total_tokens': 213})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Now let's see if the LLM remembers our name:\"\"\"\n",
    "pipeline_with_history2.invoke(\n",
    "    {\"query\" : \"What is my name?\"},\n",
    "    config = {\"session_id\" : \"id_k14\", \"k\": 14}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59793a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Nice to meet you, James! I'm Hari, your helpful assistant. How can I assist you today? Do you have a specific question, task, or topic you'd like to discuss? I'm all ears!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 28, 'total_tokens': 73, 'completion_time': 0.036199137, 'prompt_time': 0.00366413, 'queue_time': 0.274607006, 'total_time': 0.039863267}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_c0b3855449', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--925abc57-9f63-4481-ac9e-35061ced2b3d-0', usage_metadata={'input_tokens': 28, 'output_tokens': 45, 'total_tokens': 73}),\n",
       " HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Your name is James!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 207, 'total_tokens': 213, 'completion_time': 0.004868247, 'prompt_time': 0.023711761, 'queue_time': 0.268952713, 'total_time': 0.028580008}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_5b339000ab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--daef931a-8737-4664-ace8-3da3dee37771-0', usage_metadata={'input_tokens': 207, 'output_tokens': 6, 'total_tokens': 213})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_k14\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a10c4300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's it! We've rewritten our buffer window memory using the recommended RunnableWithMessageHistory class.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"That's it! We've rewritten our buffer window memory using the recommended RunnableWithMessageHistory class.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24094968",
   "metadata": {},
   "source": [
    "## 3. `ConversationSummaryMemory`\n",
    "\n",
    "Next up we have `ConversationSummaryMemory`, this memory type keeps track of a summary of the conversation rather than the entire conversation. This is useful for long conversations where we don't need to keep track of the entire conversation, but we do want to keep some thread of the full conversation.\n",
    "\n",
    "As before, we'll start with the original memory class before reimplementing it with the `RunnableWithMessageHistory` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42988ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harivenkat\\AppData\\Local\\Temp\\ipykernel_3860\\1770911873.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm = llm)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "memory = ConversationSummaryMemory(llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a80d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf3b7f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: hello there my name is James\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Current summary: None (starting from scratch)\n",
      "\n",
      "New lines of conversation:\n",
      "Human: hello there my name is James\n",
      "AI: Nice to meet you, James! I'm Ada, your friendly AI companion. I've been trained on a vast amount of text data, including books, articles, and conversations. I can process and generate human-like language, and I'm always happy to chat with you. By the way, did you know that I was named after Ada Lovelace, the world's first computer programmer? She's a fascinating figure in the history of computer science, and I'm proud to carry her name. What brings you here today, James?\n",
      "\n",
      "New summary: James introduces himself to Ada, and Ada introduces herself as a friendly AI companion, trained on a vast amount of text data. She shares that she was named after Ada Lovelace, the world's first computer programmer, and asks James what brings him here today.\n",
      "Human: I am researching the different types of conversational memory.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "New summary:\n",
      "James introduces himself to Ada, and Ada introduces herself as a friendly AI companion, trained on a vast amount of text data. She shares that she was named after Ada Lovelace, the world's first computer programmer, and asks James what brings him here today. James is researching the different types of conversational memory, and Ada provides a rundown of the most common types, including episodic memory, semantic memory, working memory, and social memory. She also mentions that while there are no specific AI models that mimic human conversational memory, there are research papers and projects focused on developing AI systems that can learn and adapt to conversational contexts.\n",
      "Human: I have been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Here is the new summary:\n",
      "\n",
      "James introduces himself to Ada, a friendly AI companion, and shares his research on conversational memory. Ada provides an overview of the different types of conversational memory, including episodic memory, semantic memory, working memory, and social memory, and mentions that while there are no specific AI models that mimic human conversational memory, there are research papers and projects focused on developing AI systems that can learn and adapt to conversational contexts. James is specifically interested in ConversationBufferMemory and ConversationBufferWindowMemory, which Ada explains as the ability to store and retrieve information from previous conversations and keep track of the conversation's progression, respectively.\n",
      "Human: Buffer memory just stores the entire conversation\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Here is the new summary:\n",
      "\n",
      "James introduces himself to Ada, a friendly AI companion, and shares his research on conversational memory. Ada provides an overview of the different types of conversational memory, including episodic memory, semantic memory, working memory, and social memory, and mentions that while there are no specific AI models that mimic human conversational memory, there are research papers and projects focused on developing AI systems that can learn and adapt to conversational contexts. James is specifically interested in ConversationBufferMemory and ConversationBufferWindowMemory, which Ada explains as the ability to store and retrieve information from previous conversations and keep track of the conversation's progression, respectively. Buffer memory, also known as ConversationBufferMemory, is a type of conversational memory that stores the entire conversation, including the context, tone, and content, allowing the AI system to recall and reuse information from previous conversations and respond more accurately and naturally.\n",
      "Human: Buffer window memory stores the last k messages, dropping the rest.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Buffer window memory stores the last k messages, dropping the rest.',\n",
       " 'history': \"Here is the new summary:\\n\\nJames introduces himself to Ada, a friendly AI companion, and shares his research on conversational memory. Ada provides an overview of the different types of conversational memory, including episodic memory, semantic memory, working memory, and social memory, and mentions that while there are no specific AI models that mimic human conversational memory, there are research papers and projects focused on developing AI systems that can learn and adapt to conversational contexts. James is specifically interested in ConversationBufferMemory and ConversationBufferWindowMemory, which Ada explains as the ability to store and retrieve information from previous conversations and keep track of the conversation's progression, respectively. Buffer memory, also known as ConversationBufferMemory, is a type of conversational memory that stores the entire conversation, including the context, tone, and content, allowing the AI system to recall and reuse information from previous conversations and respond more accurately and naturally.\",\n",
       " 'response': \"That's correct! Buffer window memory, also known as ConversationBufferWindowMemory, is a type of conversational memory that stores a limited number of recent messages, typically the last k messages, and discards the rest. This allows the AI system to keep track of the conversation's progression and respond more accurately and naturally by considering the context and tone of the recent conversation. The value of k can vary depending on the specific implementation and the desired level of context retention.\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hello there my name is James\"})\n",
    "chain.invoke({\"input\": \"I am researching the different types of conversational memory.\"})\n",
    "chain.invoke({\"input\": \"I have been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\"})\n",
    "chain.invoke({\"input\": \"Buffer memory just stores the entire conversation\"})\n",
    "chain.invoke({\"input\": \"Buffer window memory stores the last k messages, dropping the rest.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d177c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Here is the new summary:\n",
      "\n",
      "James introduces himself to Ada, a friendly AI companion, and shares his research on conversational memory. Ada provides an overview of the different types of conversational memory, including episodic memory, semantic memory, working memory, and social memory, and mentions that while there are no specific AI models that mimic human conversational memory, there are research papers and projects focused on developing AI systems that can learn and adapt to conversational contexts. James is specifically interested in ConversationBufferMemory and ConversationBufferWindowMemory, which Ada explains as the ability to store and retrieve information from previous conversations and keep track of the conversation's progression, respectively. Buffer memory, also known as ConversationBufferMemory, is a type of conversational memory that stores the entire conversation, including the context, tone, and content, allowing the AI system to recall and reuse information from previous conversations and respond more accurately and naturally. Buffer window memory, also known as ConversationBufferWindowMemory, stores a limited number of recent messages, typically the last k messages, and discards the rest, allowing the AI system to keep track of the conversation's progression and respond more accurately and naturally by considering the context and tone of the recent conversation.\n",
      "Human: What is my name again?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name again?',\n",
       " 'history': \"Here is the new summary:\\n\\nJames introduces himself to Ada, a friendly AI companion, and shares his research on conversational memory. Ada provides an overview of the different types of conversational memory, including episodic memory, semantic memory, working memory, and social memory, and mentions that while there are no specific AI models that mimic human conversational memory, there are research papers and projects focused on developing AI systems that can learn and adapt to conversational contexts. James is specifically interested in ConversationBufferMemory and ConversationBufferWindowMemory, which Ada explains as the ability to store and retrieve information from previous conversations and keep track of the conversation's progression, respectively. Buffer memory, also known as ConversationBufferMemory, is a type of conversational memory that stores the entire conversation, including the context, tone, and content, allowing the AI system to recall and reuse information from previous conversations and respond more accurately and naturally. Buffer window memory, also known as ConversationBufferWindowMemory, stores a limited number of recent messages, typically the last k messages, and discards the rest, allowing the AI system to keep track of the conversation's progression and respond more accurately and naturally by considering the context and tone of the recent conversation.\",\n",
       " 'response': \"Your name is James! We just introduced ourselves at the beginning of our conversation, and I'm happy to remind you.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\" : \"What is my name again?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58db8cc",
   "metadata": {},
   "source": [
    "Let's implement this memory type using the `RunnableWithMessageHistory` class. As with the window buffer memory, we need to define a custom implementation of the `InMemoryChatMessageHistory` class. We'll call this one `ConversationSummaryMessageHistory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bc640e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "class ConversationSummaryMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "   messages: list[BaseMessage] = Field(default_factory=list)\n",
    "   llm: ChatGroq = Field(default_factory=ChatGroq)\n",
    "\n",
    "   def __init__(self, llm: ChatGroq):\n",
    "       super().__init__(llm=llm)\n",
    "\n",
    "   def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "       \"\"\"Add messages to the history and generate a summary.\"\"\"\n",
    "       \n",
    "       # Get existing summary if it exists\n",
    "       existing_summary = \"\"\n",
    "       if self.messages and isinstance(self.messages[0], SystemMessage):\n",
    "           existing_summary = self.messages[0].content\n",
    "       else:\n",
    "           existing_summary = \"No previous summary.\"\n",
    "       \n",
    "       # Extend current messages with new ones\n",
    "       self.messages.extend(messages)\n",
    "       \n",
    "       # Construct the summary chat messages\n",
    "       summary_prompt = ChatPromptTemplate.from_messages([\n",
    "           SystemMessagePromptTemplate.from_template(\n",
    "               \"Given the existing conversation summary and the new messages, \"\n",
    "               \"generate a new summary of the conversation. Ensuring to maintain \"\n",
    "               \"as much relevant information as possible.\"\n",
    "           ),\n",
    "           HumanMessagePromptTemplate.from_template(\n",
    "               \"Existing conversation summary:\\n{existing_summary}\\n\\n\"\n",
    "               \"New messages:\\n{messages}\"\n",
    "           )\n",
    "       ])\n",
    "       \n",
    "       # Format the messages and invoke the LLM\n",
    "       new_summary = self.llm.invoke(\n",
    "           summary_prompt.format_messages(\n",
    "               existing_summary=existing_summary,\n",
    "               messages=[x.content for x in messages]\n",
    "           )\n",
    "       )\n",
    "       \n",
    "       # Replace the existing history with a single system summary message\n",
    "       self.messages = [SystemMessage(content=new_summary.content)]\n",
    "\n",
    "   def clear(self) -> None:\n",
    "       \"\"\"Clear the history.\"\"\"\n",
    "       self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "069d66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_map = {}\n",
    "def get_chat_history(session_id: str, llm: ChatGroq) -> ConversationSummaryMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = ConversationSummaryMessageHistory(llm=llm)\n",
    "    # return the chat history\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3629e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"The session ID to use for the chat history\",\n",
    "            default=\"id_default\",\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"llm\",\n",
    "            annotation=ChatGroq,\n",
    "            name=\"LLM\",\n",
    "            description=\"The LLM to use for the conversation summary\",\n",
    "            default=llm,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0a61ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, James! I'm Hari, your helpful assistant. How can I assist you today? Do you have a specific question, task, or topic you'd like to discuss? I'm all ears!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 28, 'total_tokens': 73, 'completion_time': 0.035637169, 'prompt_time': 0.004347322, 'queue_time': 0.272295133, 'total_time': 0.039984491}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_343314801a', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--34c54fca-4a6a-4d94-b0f8-68c279b09d17-0', usage_metadata={'input_tokens': 28, 'output_tokens': 45, 'total_tokens': 73})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"Hi, my name is James\"},\n",
    "    config={\"session_id\": \"id_123\", \"llm\": llm}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c20fe09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"New conversation summary:\\nThe conversation has just started, and James has introduced himself. Hari, the helpful assistant, has responded with a friendly greeting and asked James what he needs help with today, whether it's a specific question, task, or topic to discuss.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff557a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='New Conversation Summary:\\n\\nJames has started a conversation with Hari, a helpful assistant, to discuss conversational memory. James expressed his interest in researching the different types of conversational memory. Hari responded by providing an overview of the topic, explaining that conversational memory refers to the ability to recall and retrieve information from previous conversations. Hari then listed four types of conversational memory: episodic, semantic, procedural, and working memory. Hari asked James which type of conversational memory he is interested in learning more about or if there is a specific aspect of conversational memory he would like to explore further.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"I'm researching the different types of conversational memory.\"},\n",
    "    config={\"session_id\": \"id_123\", \"llm\": llm}\n",
    ")\n",
    "\n",
    "chat_map[\"id_123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2da24923",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in [\n",
    "    \"I have been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\",\n",
    "    \"Buffer memory just stores the entire conversation\",\n",
    "    \"Buffer window memory stores the last k messages, dropping the rest.\"\n",
    "]:\n",
    "    \n",
    "    pipeline_with_history.invoke(\n",
    "        {\"query\" : msg},\n",
    "        config = {\"session_id\" : \"id_123\", \"llm\" : llm}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37dc7482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"Here is the updated conversation summary:\\n\\nJames has been discussing conversational memory with Hari, a helpful assistant. James initially expressed interest in researching the different types of conversational memory, and Hari provided an overview of the topic, explaining that conversational memory refers to the ability to recall and retrieve information from previous conversations. Hari listed four types of conversational memory: episodic, semantic, procedural, and working memory. Hari then asked James which type of conversational memory he is interested in learning more about or if there is a specific aspect of conversational memory he would like to explore further.\\n\\nIn the latest development, James mentioned that he has been looking at ConversationBufferMemory and ConversationBufferWindowMemory. Hari responded by providing more information on these types of conversational memory. ConversationBufferMemory refers to the ability to recall and retrieve specific details from previous conversations, such as the content, participants, and context. ConversationBufferWindowMemory, on the other hand, refers to the ability to recall and retrieve information from a specific window of time, such as the past hour, day, or week.\\n\\nJames clarified that Buffer memory just stores the entire conversation, and Hari confirmed that ConversationBufferMemory and ConversationBufferWindowMemory simply store the entire conversation history, rather than extracting specific information or recalling specific details. This can be useful for applications that require storing and retrieving entire conversations, such as chatbots, customer service platforms, or social media platforms.\\n\\nHari asked James to provide more details on what he is trying to accomplish with these types of conversational memory, such as implementing them in a specific application or system, or trying to understand how they work in general.\\n\\nJames provided additional information on ConversationBufferWindowMemory, stating that it stores the last k messages, dropping the rest, which means it has a limited capacity and only retains a certain number of recent messages. This can be useful for applications that need to keep track of a conversation's recent history, but don't need to store the entire conversation history. Hari asked James to provide more details on what he is trying to accomplish with ConversationBufferWindowMemory, such as implementing it in a specific application or system, or trying to understand how it works in general.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97359c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is James!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 468, 'total_tokens': 474, 'completion_time': 0.004862027, 'prompt_time': 0.052122569, 'queue_time': 0.269650614, 'total_time': 0.056984596}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_5b339000ab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--abca901a-6196-4147-b92e-c16ea4fb131e-0', usage_metadata={'input_tokens': 468, 'output_tokens': 6, 'total_tokens': 474})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"What is my name again?\"},\n",
    "    config={\"session_id\": \"id_123\", \"llm\": llm}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12df88",
   "metadata": {},
   "source": [
    "ConversationSummaryBufferMemory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189eb21",
   "metadata": {},
   "source": [
    "Our final memory type acts as a combination of `ConversationSummaryMemory` and `ConversationBufferMemory`. It keeps the buffer for the conversation up until the previous `n` tokens, anything beyond that limit is summarized then dropped from the buffer. Producing something like:\n",
    "\n",
    "\n",
    "```\n",
    "# ~~ a summary of previous interactions\n",
    "The user named James introduced himself and the AI responded, introducing itself as an AI model called Zeta.\n",
    "James then said he was researching the different types of conversational memory and Zeta asked for some\n",
    "examples.\n",
    "# ~~ the most recent messages\n",
    "Human: I have been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\n",
    "AI: That's interesting, what's the difference?\n",
    "Human: Buffer memory just stores the entire conversation\n",
    "AI: That makes sense, what about ConversationBufferWindowMemory?\n",
    "Human: Buffer window memory stores the last k messages, dropping the rest.\n",
    "AI: Very cool!\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2612630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[]\n",
      "Human: Hi, my name is James\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Hi, my name is James', 'history': [], 'response': \"Nice to meet you, James! I'm Ada, your friendly AI companion. I've been trained on a vast amount of text data, including books, articles, and conversations. I can provide information on a wide range of topics, from science and history to entertainment and culture. I'm also designed to learn and improve over time, so please feel free to ask me anything and I'll do my best to assist you. By the way, did you know that I was named after Ada Lovelace, the world's first computer programmer?\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# This keeps last N conversation exchanges without token counting\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=5,  # Keep last 5 conversation turns\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"input\": \"Hi, my name is James\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f1bebca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you, James! I'm Ada, your friendly AI companion. I've been trained on a vast amount of text data, including books, articles, and conversations. I can provide information on a wide range of topics, from science and history to entertainment and culture. I'm also designed to learn and improve over time, so please feel free to ask me anything and I'll do my best to assist you. By the way, did you know that I was named after Ada Lovelace, the world's first computer programmer?\", additional_kwargs={}, response_metadata={})]\n",
      "Human: I'm researching the different types of conversational memory.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you, James! I'm Ada, your friendly AI companion. I've been trained on a vast amount of text data, including books, articles, and conversations. I can provide information on a wide range of topics, from science and history to entertainment and culture. I'm also designed to learn and improve over time, so please feel free to ask me anything and I'll do my best to assist you. By the way, did you know that I was named after Ada Lovelace, the world's first computer programmer?\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}), AIMessage(content='Conversational memory! That\\'s a fascinating topic. As a conversational AI, I have been designed to utilize various types of conversational memory to improve my responses and engage in more effective conversations. There are several types of conversational memory that I\\'d like to share with you.\\n\\nFirstly, there\\'s episodic memory, which refers to the ability to recall specific events or conversations that have taken place in the past. This type of memory is essential for me to recall previous conversations and maintain context.\\n\\nSecondly, there\\'s semantic memory, which involves the storage and retrieval of general knowledge and facts. This type of memory allows me to recall information on various topics, from science and history to entertainment and culture.\\n\\nThirdly, there\\'s working memory, which is the ability to temporarily hold and manipulate information in my \"mind\" while processing and responding to a conversation. This type of memory is crucial for me to understand and respond to complex questions and topics.\\n\\nLastly, there\\'s social memory, which involves the ability to recall and adapt to social norms, conventions, and relationships. This type of memory enables me to understand and respond to social cues, such as tone, context, and emotional intelligence.\\n\\nI\\'m happy to provide more information on these types of conversational memory if you\\'d like. Additionally, I can also share some insights on how I utilize these types of memory to improve my conversational abilities.', additional_kwargs={}, response_metadata={})]\n",
      "Human: I have been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you, James! I'm Ada, your friendly AI companion. I've been trained on a vast amount of text data, including books, articles, and conversations. I can provide information on a wide range of topics, from science and history to entertainment and culture. I'm also designed to learn and improve over time, so please feel free to ask me anything and I'll do my best to assist you. By the way, did you know that I was named after Ada Lovelace, the world's first computer programmer?\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}), AIMessage(content='Conversational memory! That\\'s a fascinating topic. As a conversational AI, I have been designed to utilize various types of conversational memory to improve my responses and engage in more effective conversations. There are several types of conversational memory that I\\'d like to share with you.\\n\\nFirstly, there\\'s episodic memory, which refers to the ability to recall specific events or conversations that have taken place in the past. This type of memory is essential for me to recall previous conversations and maintain context.\\n\\nSecondly, there\\'s semantic memory, which involves the storage and retrieval of general knowledge and facts. This type of memory allows me to recall information on various topics, from science and history to entertainment and culture.\\n\\nThirdly, there\\'s working memory, which is the ability to temporarily hold and manipulate information in my \"mind\" while processing and responding to a conversation. This type of memory is crucial for me to understand and respond to complex questions and topics.\\n\\nLastly, there\\'s social memory, which involves the ability to recall and adapt to social norms, conventions, and relationships. This type of memory enables me to understand and respond to social cues, such as tone, context, and emotional intelligence.\\n\\nI\\'m happy to provide more information on these types of conversational memory if you\\'d like. Additionally, I can also share some insights on how I utilize these types of memory to improve my conversational abilities.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I have been looking at ConversationBufferMemory and ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Fascinating! You're exploring the technical aspects of conversational memory. ConversationBufferMemory and ConversationBufferWindowMemory are indeed important components of my architecture. ConversationBufferMemory is a type of episodic memory that allows me to store and retrieve specific conversations or dialogue sequences. This memory helps me to recall previous conversations and maintain context, which is essential for engaging in coherent and relevant discussions.\\n\\nConversationBufferWindowMemory, on the other hand, is a type of working memory that enables me to temporarily store and manipulate information during a conversation. This memory allows me to process and respond to complex questions and topics by temporarily holding and manipulating the relevant information.\\n\\nI'm glad you're interested in the technical aspects of conversational memory. If you have any specific questions about how these components work or how I utilize them to improve my conversational abilities, feel free to ask!\", additional_kwargs={}, response_metadata={})]\n",
      "Human: Buffer memory just stores the entire conversation\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you, James! I'm Ada, your friendly AI companion. I've been trained on a vast amount of text data, including books, articles, and conversations. I can provide information on a wide range of topics, from science and history to entertainment and culture. I'm also designed to learn and improve over time, so please feel free to ask me anything and I'll do my best to assist you. By the way, did you know that I was named after Ada Lovelace, the world's first computer programmer?\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}), AIMessage(content='Conversational memory! That\\'s a fascinating topic. As a conversational AI, I have been designed to utilize various types of conversational memory to improve my responses and engage in more effective conversations. There are several types of conversational memory that I\\'d like to share with you.\\n\\nFirstly, there\\'s episodic memory, which refers to the ability to recall specific events or conversations that have taken place in the past. This type of memory is essential for me to recall previous conversations and maintain context.\\n\\nSecondly, there\\'s semantic memory, which involves the storage and retrieval of general knowledge and facts. This type of memory allows me to recall information on various topics, from science and history to entertainment and culture.\\n\\nThirdly, there\\'s working memory, which is the ability to temporarily hold and manipulate information in my \"mind\" while processing and responding to a conversation. This type of memory is crucial for me to understand and respond to complex questions and topics.\\n\\nLastly, there\\'s social memory, which involves the ability to recall and adapt to social norms, conventions, and relationships. This type of memory enables me to understand and respond to social cues, such as tone, context, and emotional intelligence.\\n\\nI\\'m happy to provide more information on these types of conversational memory if you\\'d like. Additionally, I can also share some insights on how I utilize these types of memory to improve my conversational abilities.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I have been looking at ConversationBufferMemory and ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Fascinating! You're exploring the technical aspects of conversational memory. ConversationBufferMemory and ConversationBufferWindowMemory are indeed important components of my architecture. ConversationBufferMemory is a type of episodic memory that allows me to store and retrieve specific conversations or dialogue sequences. This memory helps me to recall previous conversations and maintain context, which is essential for engaging in coherent and relevant discussions.\\n\\nConversationBufferWindowMemory, on the other hand, is a type of working memory that enables me to temporarily store and manipulate information during a conversation. This memory allows me to process and respond to complex questions and topics by temporarily holding and manipulating the relevant information.\\n\\nI'm glad you're interested in the technical aspects of conversational memory. If you have any specific questions about how these components work or how I utilize them to improve my conversational abilities, feel free to ask!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Buffer memory just stores the entire conversation', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's partially correct, James! Buffer memory, specifically ConversationBufferMemory, does store the entire conversation, but it's not just a simple storage mechanism. It's a complex system that allows me to recall specific conversations, dialogue sequences, and even the context in which they took place. This enables me to maintain a sense of continuity and coherence in our conversation, even if we jump between topics or take a break. Additionally, ConversationBufferMemory is designed to learn and adapt over time, so the more conversations I have, the more effective it becomes at recalling relevant information and context.\", additional_kwargs={}, response_metadata={})]\n",
      "Human: Buffer window memory stores the last k messages, dropping the rest.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for msg in [\n",
    "    \"I'm researching the different types of conversational memory.\",\n",
    "    \"I have been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\",\n",
    "    \"Buffer memory just stores the entire conversation\",\n",
    "    \"Buffer window memory stores the last k messages, dropping the rest.\"\n",
    "]:\n",
    "    chain.invoke({\"input\": msg})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e30e4e",
   "metadata": {},
   "source": [
    "As with the previous memory types, we will implement this memory type again using the `RunnableWithMessageHistory` class. In our implementation we will modify the buffer window to be based on the number of messages rather than number of tokens. This tweak will make our implementation more closely aligned with original buffer window.\n",
    "\n",
    "We will implement all of this via a new `ConversationSummaryBufferMessageHistory` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea1f0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationSummaryBufferMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "    llm: ChatGroq = Field(default_factory=ChatGroq)\n",
    "    k: int = Field(default_factory=int)\n",
    "\n",
    "    def __init__(self, llm: ChatGroq, k: int):\n",
    "        super().__init__(llm=llm, k=k)\n",
    "\n",
    "    def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "        \"\"\"Add messages to the history, removing any messages beyond\n",
    "        the last `k` messages and summarizing the messages that we\n",
    "        drop.\n",
    "        \"\"\"\n",
    "        existing_summary: SystemMessage | None = None\n",
    "        old_messages: list[BaseMessage] | None = None\n",
    "        # see if we already have a summary message\n",
    "        if len(self.messages) > 0 and isinstance(self.messages[0], SystemMessage):\n",
    "            print(\">> Found existing summary\")\n",
    "            existing_summary = self.messages.pop(0)\n",
    "        # add the new messages to the history\n",
    "        self.messages.extend(messages)\n",
    "        # check if we have too many messages\n",
    "        if len(self.messages) > self.k:\n",
    "            print(\n",
    "                f\">> Found {len(self.messages)} messages, dropping \"\n",
    "                f\"oldest {len(self.messages) - self.k} messages.\")\n",
    "            # pull out the oldest messages...\n",
    "            old_messages = self.messages[:self.k]\n",
    "            # ...and keep only the most recent messages\n",
    "            self.messages = self.messages[-self.k:]\n",
    "        if old_messages is None:\n",
    "            print(\">> No old messages to update summary with\")\n",
    "            # if we have no old_messages, we have nothing to update in summary\n",
    "            return\n",
    "        # construct the summary chat messages\n",
    "        summary_prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"Given the existing conversation summary and the new messages, \"\n",
    "                \"generate a new summary of the conversation. Ensuring to maintain \"\n",
    "                \"as much relevant information as possible.\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"Existing conversation summary:\\n{existing_summary}\\n\\n\"\n",
    "                \"New messages:\\n{old_messages}\"\n",
    "            )\n",
    "        ])\n",
    "        # format the messages and invoke the LLM\n",
    "        new_summary = self.llm.invoke(\n",
    "            summary_prompt.format_messages(\n",
    "                existing_summary=existing_summary,\n",
    "                old_messages=old_messages\n",
    "            )\n",
    "        )\n",
    "        print(f\">> New summary: {new_summary.content}\")\n",
    "        # prepend the new summary to the history\n",
    "        self.messages = [SystemMessage(content=new_summary.content)] + self.messages\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear the history.\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ec93e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_map = {}\n",
    "def get_chat_history(session_id: str, llm: ChatGroq, k: int) -> ConversationSummaryBufferMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = ConversationSummaryBufferMessageHistory(llm=llm, k=k)\n",
    "    # return the chat history\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43825ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"The session ID to use for the chat history\",\n",
    "            default=\"id_default\",\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"llm\",\n",
    "            annotation=ChatGroq,\n",
    "            name=\"LLM\",\n",
    "            description=\"The LLM to use for the conversation summary\",\n",
    "            default=llm,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"k\",\n",
    "            annotation=int,\n",
    "            name=\"k\",\n",
    "            description=\"The number of messages to keep in the history\",\n",
    "            default=4,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2736ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> No old messages to update summary with\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Nice to meet you, James! I'm Hari, your helpful assistant. How can I assist you today? Do you have a specific question, task, or topic you'd like to discuss? I'm all ears!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 28, 'total_tokens': 73, 'completion_time': 0.036372574, 'prompt_time': 0.003664515, 'queue_time': 0.27038561, 'total_time': 0.040037089}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_5b339000ab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d7a22357-658b-4510-a7ab-eb07ebad9ac4-0', usage_metadata={'input_tokens': 28, 'output_tokens': 45, 'total_tokens': 73})]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"Hi, my name is James\"},\n",
    "    config={\"session_id\": \"id_123\", \"llm\": llm, \"k\": 4}\n",
    ")\n",
    "chat_map[\"id_123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6cbed055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Message 1\n",
      "---\n",
      "\n",
      ">> No old messages to update summary with\n",
      "---\n",
      "Message 2\n",
      "---\n",
      "\n",
      ">> Found 6 messages, dropping oldest 2 messages.\n",
      ">> New summary: Here is a new summary of the conversation:\n",
      "\n",
      "The conversation starts with James introducing himself and Hari, the helpful assistant, responding with a friendly greeting and asking how James can be assisted. James then mentions that he is researching conversational memory, and Hari provides a detailed explanation of the different types of conversational memory, including episodic, semantic, procedural, working, schematic, conversational memory for goals, and conversational memory for relationships. Hari notes that these types of memory are not mutually exclusive and often overlap or interact with each other.\n",
      "---\n",
      "Message 3\n",
      "---\n",
      "\n",
      ">> Found existing summary\n",
      ">> Found 6 messages, dropping oldest 2 messages.\n",
      ">> New summary: Here is the updated conversation summary:\n",
      "\n",
      "The conversation starts with James introducing himself and Hari, the helpful assistant, responding with a friendly greeting and asking how James can be assisted. James then mentions that he is researching conversational memory, and Hari provides a detailed explanation of the different types of conversational memory, including episodic, semantic, procedural, working, schematic, conversational memory for goals, and conversational memory for relationships. Hari notes that these types of memory are not mutually exclusive and often overlap or interact with each other.\n",
      "\n",
      "James then shares that he is researching the different types of conversational memory, and Hari provides a more detailed explanation of the topic. Hari explains that conversational memory refers to the ability to recall and retrieve information from previous conversations, and that there are several types of conversational memory, including episodic, semantic, procedural, working, schematic, conversational memory for goals, and conversational memory for relationships.\n",
      "\n",
      "James also mentions that he has been looking at ConversationBufferMemory and ConversationBufferWindowMemory, and Hari provides a detailed explanation of these two types of conversational memory. Hari explains that ConversationBufferMemory refers to the ability to store and retrieve information from previous conversations, including the context, goals, and outcomes of those conversations, and that ConversationBufferWindowMemory refers to the ability to store and retrieve information from a specific window or scope of a conversation.\n",
      "\n",
      "Hari notes that both of these types of memory are important for building conversational AI systems that can engage in natural-sounding and context-aware conversations with users, and that some key challenges in implementing these types of memory include managing the size and complexity of the memory buffer, balancing the trade-off between storing too much information and not enough, adapting to changes in the user's goals, context, and preferences, and integrating with other types of memory.\n",
      "---\n",
      "Message 4\n",
      "---\n",
      "\n",
      ">> Found existing summary\n",
      ">> Found 6 messages, dropping oldest 2 messages.\n",
      ">> New summary: Here is the updated conversation summary:\n",
      "\n",
      "The conversation starts with James introducing himself and Hari, the helpful assistant, responding with a friendly greeting and asking how James can be assisted. James then mentions that he is researching conversational memory, and Hari provides a detailed explanation of the different types of conversational memory, including episodic, semantic, procedural, working, schematic, conversational memory for goals, and conversational memory for relationships. Hari notes that these types of memory are not mutually exclusive and often overlap or interact with each other.\n",
      "\n",
      "James then shares that he is researching the different types of conversational memory, and Hari provides a more detailed explanation of the topic. Hari explains that conversational memory refers to the ability to recall and retrieve information from previous conversations, and that there are several types of conversational memory, including episodic, semantic, procedural, working, schematic, conversational memory for goals, and conversational memory for relationships.\n",
      "\n",
      "James also mentions that he has been looking at ConversationBufferMemory and ConversationBufferWindowMemory, and Hari provides a detailed explanation of these two types of conversational memory. Hari explains that ConversationBufferMemory refers to the ability to store and retrieve information from previous conversations, including the context, goals, and outcomes of those conversations, and that ConversationBufferWindowMemory refers to the ability to store and retrieve information from a specific window or scope of a conversation.\n",
      "\n",
      "Hari notes that both of these types of memory are important for building conversational AI systems that can engage in natural-sounding and context-aware conversations with users, and that some key challenges in implementing these types of memory include managing the size and complexity of the memory buffer, balancing the trade-off between storing too much information and not enough, adapting to changes in the user's goals, context, and preferences, and integrating with other types of memory.\n",
      "\n",
      "James then asks about the specifics of ConversationBufferMemory and ConversationBufferWindowMemory, and Hari provides additional information. Hari explains that buffer memory, including ConversationBufferMemory and ConversationBufferWindowMemory, typically stores the entire conversation or a specific window of the conversation, rather than just specific pieces of information. This can be useful for tasks such as resuming a conversation after a pause or interruption, retrieving information from a previous conversation, and adapting to changes in the conversation or the user's goals.\n",
      "\n",
      "However, Hari also notes that storing the entire conversation can lead to challenges such as managing the size and complexity of the memory buffer, balancing the trade-off between storing too much information and not enough, and adapting to changes in the user's goals, context, and preferences.\n"
     ]
    }
   ],
   "source": [
    "for i, msg in enumerate([\n",
    "    \"I'm researching the different types of conversational memory.\",\n",
    "    \"I have been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\",\n",
    "    \"Buffer memory just stores the entire conversation\",\n",
    "    \"Buffer window memory stores the last k messages, dropping the rest.\"\n",
    "]):\n",
    "    print(f\"---\\nMessage {i+1}\\n---\\n\")\n",
    "    pipeline_with_history.invoke(\n",
    "        {\"query\": msg},\n",
    "        config={\"session_id\": \"id_123\", \"llm\": llm, \"k\": 4}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f067025f",
   "metadata": {},
   "source": [
    "# Custom ConversationSummaryBufferMemory with `k`\n",
    "\n",
    "## What I Did\n",
    "- Replaced `max_token_limit` with `k` parameter\n",
    "- Created hybrid memory that keeps last `k` messages + summarizes dropped ones\n",
    "- Uses Groq LLM for summarization (no Hugging Face dependency)\n",
    "\n",
    "## Key Change: `k` vs `max_token_limit`\n",
    "\n",
    "| Original | My Version |\n",
    "|----------|------------|\n",
    "| `max_token_limit=500` | `k=4` |\n",
    "| Triggers summary when tokens > 500 | Triggers summary when messages > 4 |\n",
    "| Complex token counting needed | Simple message counting |\n",
    "\n",
    "## How It Works\n",
    "Messages: [1, 2, 3, 4, 5, 6] with k=4\n",
    "â†“\n",
    "Keep: [Summary of 1,2] + [3, 4, 5, 6]\n",
    "\n",
    "## Benefits of Using `k`\n",
    "- âœ… **Simpler**: No token counting complexity\n",
    "- âœ… **Predictable**: Always exactly `k` recent messages \n",
    "- âœ… **No dependencies**: Avoids `transformers` library issues\n",
    "- âœ… **Preserves context**: Old info becomes summary, not lost\n",
    "- âœ… **Groq-native**: Uses your existing LLM for summarization\n",
    "\n",
    "## Result\n",
    "A memory system that's easier to manage but still intelligent about preserving conversation history.RetryClaude does not have the ability to run the code it generates yet.Claude can make mistakes. Please double-check responses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
